{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the method\n",
    "### Assumptions\n",
    "*Unconfoundedness*\\:  \n",
    "　　Treatment status within the final groups of firms (partitions) trees calculate is random.\n",
    "$$\n",
    "\\left[\n",
    "W_{i} \\perp\\!\\!\\!\\perp \\left(Y_{i}(0), Y_{i}(1)\\right) \\mid X_{i}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "### Notation\n",
    "*Average Treatment Effect (ATE)*\\:\n",
    "$$ATE=\\mathbb{E}[\\beta]=\\mathbb{E}[Y_1]-\\mathbb{E}[Y_0] $$\n",
    "$$Y_i=Y_{0i}+(Y_{1i}-Y_{0i})W_i $$\n",
    "\n",
    "\\begin{eqnarray*} \\underset{\\mbox{ Observed Differences in Earnings}}{\\mathbb{E}[Y_{i}|W=1]-\\mathbb{E}[Y_i|W=0]}&=&\\underset{\\mbox{ Average treatment effect on the treated}}{\\mathbb{E}[Y_{1i}-Y_{0i}|W=1]}\\\\ &-&\\underset{\\mbox{ Selection Bias}}{\\mathbb{E}[Y_{0i}|W=1]-\\mathbb{E}[Y_{0i}|W=0]}\\end{eqnarray*}\n",
    "\n",
    "*Conditional Average Treatment Effect (CATE)*\\:  \n",
    "　　The conditional average treatment effect function is:  \n",
    "$$\\tau(x)=\\mathbb{E}\\left[Y_{i}(1)-Y_{i}(0) \\mid X_{i}=x\\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Motivation\n",
    " \n",
    "　　I generate the data referring to the essay, and its DGP comes from the essay:   \n",
    "- Huseyin Guleny, Candace E. Jensz, T. Beau Pagex, An application of causal forest in corporate finance: How does financing affect investment? ,2020.04.23.  \n",
    " \n",
    "　　Theoretical references:  \n",
    "- Athey, S., Imbens, G., 2016. Recursive partitioning for heterogeneous causal effects. Proceedings of the National Academy of Sciences 113, 7353-7360.  \n",
    "- GuidoWImbens & Donald B Rubin. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press, 2015.  \n",
    "- Stefan Wager & Susan Athey. Estimation and Inference of Heterogeneous Treatment Effects using Random Forests. Journal of the American Statistical Association, 0162-1459.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Project\n",
    "　　This project aims to compare how well OLS and causal forest work in different situations. Here I will change several sample sizes and models to show the difference.  \n",
    "　　This project compares the linear and non-linear specification estimations respectively, along three dimensions: bias, precision, and coverage. I measure bias as the difference between the estimated ATE and the true value of ATE of each model, with confidence interval under 97.5% confidence level. Precision is the root mean squared error (RMSE), measured as the standard deviation of the difference between the estimate and the true value. Coverage is the fraction of trials in which a t-test of the estimate compared to the true value rejects at the 5% level.  \n",
    "　　I visualize bias by line/point/box plots, and present precision (RMSE) and coverage in tables. All else equal, we prefer an estimator with zero bias, low RMSE, and test coverage of 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list = ls())\n",
    "options(warn =-1)\n",
    "if (!require(\"grf\")) install.packages(\"grf\")\n",
    "if (!require(\"DiagrammeR\")) install.packages(\"DiagrammeR\")\n",
    "if (!require(\"akima\")) install.packages(\"akima\")\n",
    "if (!require(\"plotly\")) install.packages(\"plotly\")\n",
    "library(MASS)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(purrr)\n",
    "library(cowplot)\n",
    "set.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: linear model   \n",
    "$$y = 0.05x_1 - 0.005x_2 + 0.01x_3 + 0.02D + \\varepsilon$$\n",
    "\n",
    "　　$y$ is the dependent variable, the three $x$ variables are additional covariates, $D$ is a\n",
    "binary variable equal to one if the forcing variable $d$ is greater than zero. I simulate the $x$ and $d$ variables using a multivariate normal distribution. For the vector\n",
    "$(x1, x2, x3, d)$, I set the mean to (1.40, 5.50, 0.10, 0.20), standard deviation to (1.00, 1.50, 0.30, 0.30),\n",
    "and use the correlation matrix:\n",
    "\\begin{bmatrix}\n",
    "1.00&-0.05&-0.30& 0.15 \\\\\n",
    "-0.05& 1.00& 0.20& 0.35 \\\\\n",
    "-0.30& 0.20& 1.00& 0.50 \\\\\n",
    "0.15& 0.35& 0.50& 1.00\n",
    "\\end{bmatrix}\n",
    "The $\\varepsilon$ term has a mean of zero and a standard deviation\n",
    "of 0.065."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 1 ###\n",
    "# y = 0.05x1 - 0.005x2 + 0.01x3 + 0.02D + eps \n",
    "dgp_model1 <- function(N){\n",
    "  # mean, standard deviation, correlation matrix for generate (x1,x2,x3,d) using mvrnorm\n",
    "  mu <- c(1.40, 5.50, 0.10, 0.20)\n",
    "  sd <- c(1.00, 1.50, 0.30, 0.30)\n",
    "  cor_matrix <- matrix(c( 1.00,-0.05,-0.30, 0.15,\n",
    "                         -0.05, 1.00, 0.20, 0.35,\n",
    "                         -0.30, 0.20, 1.00, 0.50,\n",
    "                          0.15, 0.35, 0.50, 1.00), nrow = 4, ncol = 4)\n",
    "  beta <- c(0.05, -0.005, 0.01, 0.02) # for x1,x2,x3,D\n",
    "  # gerate covariation matrix using standard error and correlation matrix\n",
    "  cov_matrix <- diag(sd) %*% cor_matrix %*% diag(sd)\n",
    "  # generate x1,x2,x3,d\n",
    "  mvnorm_data <- mvrnorm(n = N, mu = mu, Sigma = cov_matrix)\n",
    "  # generate X : (x1, x2, x3)\n",
    "  poly_max <- 1\n",
    "  X <- reduce( c(1,1:poly_max), \n",
    "               function(X, poly)\n",
    "                 cbind(X, mvnorm_data[,1]^poly, mvnorm_data[,2]^poly, mvnorm_data[,3]^poly)\n",
    "  ) %>% subset(select = -c(1))\n",
    "  if(poly_max == 1) {\n",
    "    colnames(X) <- c(\"x1\",\"x2\",\"x3\")\n",
    "  } else {\n",
    "    colnames(X) <- rep(c(\"x1\",\"x2\",\"x3\"), poly_max - 1) %>%\n",
    "      paste0(c(rep(\"\", 3),rep(paste0(\"^\", 2:poly_max), each = 3)))\n",
    "  }\n",
    "  \n",
    "  D <- as.integer(mvnorm_data[,4] > 0)\n",
    "  X <- cbind(X, D)\n",
    "  eps <- rnorm(N, 0, 0.065)\n",
    "  y <- X %*% beta + eps\n",
    "  X <- subset(X, select = c(x1, x2, x3, D))\n",
    "  \n",
    "  beta.true <- 0.02\n",
    "  return(list(X=X, y=y, d=mvnorm_data[,4], beta.true=beta.true))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　To get ATE, bias, RMSE, confidence interval and coverage from ols and causal forest, I write this two function. $X$ is a data frame with x1,x2,x3 and D generated from DGP. $y$ is true y. $beta.true$ is a fixed number for every certain DGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#### Method Comparison ####\n",
    "###########################\n",
    "\n",
    "ols<-function(X, y, beta.true){\n",
    "  X <- cbind(1, X)\n",
    "  lm <- lm(data = data.frame(X, y), \"y ~ x1 + x2 + x3 + D\")\n",
    "  su <- summary(lm)\n",
    "  beta.hat <- su$coefficients[,\"Estimate\"]\n",
    "  y.hat <- lm$fitted.values\n",
    "  se <- su$coefficients[,\"Std. Error\"]\n",
    "  RMSE <- sqrt(sum(su$residuals ^ 2) / length(y))\n",
    "  if(nrow(su$coefficients) < 5){\n",
    "    print(\"coefficients is empty\")\n",
    "  }\n",
    "  coverage <- su$coefficients[\"D\", 4]\n",
    "  ATE <- beta.hat[\"D\"]\n",
    "  bias <- abs(ATE - beta.true) / beta.true * 100\n",
    "  \n",
    "  #95% CI of coefficient of D\n",
    "  upper <- beta.hat[\"D\"] + qnorm(0.975) * se[\"D\"]\n",
    "  lower <- beta.hat[\"D\"] - qnorm(0.975) * se[\"D\"]\n",
    "  \n",
    "  return(list(ATE = ATE, bias = bias, CI = c(lower, upper), RMSE = RMSE, coverage = coverage))\n",
    "}\n",
    "\n",
    "forest<-function(X, y, beta.true){\n",
    "  Y <- y\n",
    "  W <- X[, \"D\"]\n",
    "  X <- subset(X, select = c(x1, x2, x3))\n",
    "  \n",
    "  Y.forest <- regression_forest(X, Y)\n",
    "  Y.hat <- predict(Y.forest)$predictions\n",
    "  W.forest <- regression_forest(X, W)\n",
    "  W.hat <- predict(W.forest)$predictions\n",
    "  \n",
    "  cf <- causal_forest(X, Y, W, Y.hat = Y.hat, W.hat = W.hat)\n",
    "  tau.hat <- predict(cf)$predictions\n",
    "  ATE.forest <- average_treatment_effect(cf)\n",
    "  tree <- get_tree(cf, 1)\n",
    "  \n",
    "  #95% CI of ATE\n",
    "  upper <- ATE.forest[1] + qnorm(0.975) * ATE.forest[2]\n",
    "  lower <- ATE.forest[1] - qnorm(0.975) * ATE.forest[2]\n",
    "  \n",
    "  RMSE <- sqrt(sum((y - Y.hat) ^ 2) / length(y))\n",
    "  \n",
    "  ATE <- ATE.forest[1]\n",
    "  bias <- abs(ATE - beta.true) / beta.true * 100\n",
    "  \n",
    "  test <- test_calibration(cf)\n",
    "  coverage <- test[1,4]\n",
    "  return(list(ATE = ATE, bias = bias, CI = c(lower, upper), RMSE = RMSE, coverage = coverage, tree=tree, tau.hat=tau.hat))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　Simulation function is used for quickly generating plot data, by inputting a vector of sample size and a number for iteration times for every data size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "####    Simulation     ####\n",
    "###########################\n",
    "# Quickly generate plot data.\n",
    "# Args:\n",
    "#   sim.times: Number for iteration times for every data size.\n",
    "#   data.size: Vector of sample size for simulation.\n",
    "#   dgp_func: Function to generate X, y, beta.true, such as \"dgp_model1\"\n",
    "# Returns:\n",
    "#   Data frame contains ols and causal forest result for every data size and simulation time.\n",
    "simulation <- function(sim.times, data.size, dgp_func){\n",
    "  plot.data<-data.frame(ATE = rep(NA, sim.times * length(data.size) * 2), \n",
    "                        RMSE = NA,\n",
    "                        CI_lower = NA,\n",
    "                        CI_upper = NA,\n",
    "                        bias = NA,\n",
    "                        coverage = NA,\n",
    "                        method = factor(x=rep(c(\"ols\", \"forest\"), sim.times * length(data.size)), levels = c(\"ols\", \"forest\")), \n",
    "                        sim.time = rep(1:sim.times, each = 2, times = length(data.size)),\n",
    "                        N = rep(data.size, each = 2 * sim.times))\n",
    "  index <- 0\n",
    "  for(j in 1:length(data.size)){\n",
    "    N = data.size[j]\n",
    "    for(i in 1:sim.times){\n",
    "      sim.data <- dgp_func(N)\n",
    "      \n",
    "      index <- index + 1\n",
    "      result.ols<-ols(sim.data$X, sim.data$y, sim.data$beta.true)\n",
    "      plot.data$ATE[index] <- result.ols$ATE\n",
    "      plot.data$RMSE[index] <- result.ols$RMSE\n",
    "      plot.data$CI_lower[index] <- result.ols$CI[1]\n",
    "      plot.data$CI_upper[index] <- result.ols$CI[2]\n",
    "      plot.data$bias[index] <- result.ols$bias\n",
    "      plot.data$coverage[index] <- result.ols$coverage\n",
    "      \n",
    "      index <- index + 1\n",
    "      result.cf<- forest(sim.data$X, sim.data$y, sim.data$beta.true)\n",
    "      plot.data$ATE[index] <- result.cf$ATE\n",
    "      plot.data$RMSE[index] <- result.cf$RMSE\n",
    "      plot.data$CI_lower[index] <- result.cf$CI[1]\n",
    "      plot.data$CI_upper[index] <- result.cf$CI[2]\n",
    "      plot.data$bias[index] <- result.cf$bias\n",
    "      plot.data$coverage[index] <- result.cf$coverage\n",
    "    }\n",
    "  }\n",
    "  return(plot.data)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 1: modify sample size from 500 to 15000.**  \n",
    "\\* *I use loops in R, but here for convenience I change loops into normal codes to show the intermediate results.*  \n",
    "\\* *Simulation 1 takes hours to run. Change data.size1 for quick look.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size1 <- seq(500, 15000, 100)\n",
    "sim.data.list1 <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model1\n",
    "name <- \"model 1\"\n",
    "i <- 1\n",
    "\n",
    "# generate plot data\n",
    "sim.data <- simulation(sim.times = 1, data.size = data.size1, dgp_func)\n",
    "# sim.data <- sim.data.list1[[i]] # for replay\n",
    "sim.data.list1[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# bias line plot\n",
    "plot_bias <- ggplot(sim.data, aes(N)) +\n",
    "    geom_line(aes(y = bias, color = method)) +\n",
    "    ylim(min(sim.data$bias), max(sim.data$bias)) +\n",
    "    labs(title = paste0(name, \" bias\"))\n",
    "print(plot_bias)\n",
    "\n",
    "# ATE line plot\n",
    "plot_ATE <- ggplot(sim.data, aes(N)) +\n",
    "    geom_line(aes(y = ATE, color = method), cex = 1) +\n",
    "    geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper, fill = method), alpha = 0.1) +\n",
    "    geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "    ylim(min(sim.data$CI_lower), max(sim.data$CI_upper)) +\n",
    "    labs(title = paste0(name, \" ATE\"))\n",
    "print(plot_ATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 2: use (500, 1000, 5000, 10000) for sample size and iterate 1000 for every sample size**  \n",
    "\\* *Simulation 2 takes hours to run. Change sim.times for quick look.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size2 <- c(500, 1000, 5000, 10000)\n",
    "sim.data.list2 <- list()\n",
    "mean_sim2 <- data.frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model1\n",
    "name <- \"model 1\"\n",
    "i <- 1\n",
    "\n",
    "sim.data <- simulation(sim.times = 1000, data.size = data.size2, dgp_func)\n",
    "# sim.data <- sim.data.list2[[i]] # for replay\n",
    "sim.data.list2[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# generate point and box plot for every data size\n",
    "ATE_point_plot.list <- list()\n",
    "ATE_box_plot.list <- list()\n",
    "for(j in 1:length(data.size2)){\n",
    "    N <- data.size2[j]\n",
    "    plot.heigth <- max(beta.true - min(sim.data$ATE), max(sim.data$ATE) - beta.true)\n",
    "    ATE_point_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(sim.time)) +\n",
    "      geom_point(aes(y = ATE, color = method, shape = method)) +\n",
    "      geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "      ylim(beta.true - plot.heigth, beta.true + plot.heigth) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = \"iteration\", y = \"ATE\")\n",
    "\n",
    "    ATE_box_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(method)) +\n",
    "      geom_boxplot(aes(y = ATE, color = method)) +\n",
    "      ylim(min(sim.data$ATE), max(sim.data$ATE)) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = NULL)\n",
    "}\n",
    "title <- ggdraw() + \n",
    "    draw_label(name, fontface = 'bold', x = 0, hjust = 0) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 20))\n",
    "ATE_point_plot <- plot_grid(plotlist = ATE_point_plot.list)\n",
    "ATE_box_plot <- plot_grid(plotlist = ATE_box_plot.list)\n",
    "# ATE_point.png\n",
    "print(plot_grid(title, ATE_point_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "# ATE_box.png\n",
    "print(plot_grid(title, ATE_box_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "\n",
    "# generate mean of simulation result data\n",
    "sim.data_grouped <- group_by(sim.data, method, N)\n",
    "mean_by_method_N <- summarize(sim.data_grouped, ATE = mean(ATE,na.rm=TRUE), RMSE = mean(RMSE,na.rm=TRUE), bias = mean(bias,na.rm=TRUE),\n",
    "                                   coverage = mean(coverage,na.rm=TRUE)) %>% mutate(model = name)\n",
    "mean_sim2 <- rbind(mean_sim2, mean_by_method_N)\n",
    "print(mean_by_method_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　Simulations for the linear base case demonstrate the following: we can see from plots and table that OLS is the best estimator for sample size of 500 to 5000, since causal forest has higher variance and performs more unstable than OLS.  \n",
    "　　As sample size increases, MSE decreases for both ols and causal forest, and causal forest is the dominant estimator in large sample size.  \n",
    "　　Although causal forest and ols have comparable mse for all sample sizes, causal forest deceases its bias as sample size increases and it has lower bias than ols at sample size of 10000. This is because causal forest is data hungry and thus needs large sample size to work well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　To better understand the tree method, I draw a tree plot to show how causal forest works in this process with a sample size of 1000. It shows the sample size as well as the average value of W (ATE) in each branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tree\n",
    "dgp_func <- dgp_model1\n",
    "name <- \"model 1\"\n",
    "sim.data <- dgp_func(1000)\n",
    "result.cf<- forest(sim.data$X, sim.data$y, sim.data$beta.true)\n",
    "plot(result.cf$tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: polynomial specification\n",
    "$$y=0.05 x_{1}-0.005 x_{2}+0.01 x_{3}+0.025 x_{1}^{2}-0.01 x_{2}^{2}+0.015 x_{3}^{2}+0.02 D+\\varepsilon$$\n",
    "\n",
    "　　In the following models we will have misspecification problem. Therefore, the treatment effect is biased for OLS model. However, causal forest works pretty well in heterogenous designed model and its ATE value is closer to the true value. We can see from the plots that ATE in OLS (green line) is always waving above the true value, while causal forest (red line) has a fluctuation up and down the true value line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 2 ###\n",
    "# y = 0.05x1 + 0.005x2 + 0.01x3 + 0.025x1^2 + 0.01x2^2 + 0.015x3^2 + 0.02D + eps \n",
    "dgp_model2 <- function(N){\n",
    "  # mean, standard deviation, correlation matrix for generate (x1,x2,x3,d) using mvrnorm\n",
    "  mu <- c(1.40, 5.50, 0.10, 0.20)\n",
    "  sd <- c(1.00, 1.50, 0.30, 0.30)\n",
    "  cor_matrix <- matrix(c( 1.00,-0.05,-0.30, 0.15,\n",
    "                         -0.05, 1.00, 0.20, 0.35,\n",
    "                         -0.30, 0.20, 1.00, 0.50,\n",
    "                          0.15, 0.35, 0.50, 1.00), nrow = 4, ncol = 4)\n",
    "  beta <- c(0.05, -0.005, 0.01, 0.025, -0.01, 0.015, 0.02) # for x1,x2,x3,x1^2,x2^2,x3^2,D\n",
    "  # gerate covariation matrix using standard error and correlation matrix\n",
    "  cov_matrix <- diag(sd) %*% cor_matrix %*% diag(sd)\n",
    "  # generate x1,x2,x3,d\n",
    "  mvnorm_data <- mvrnorm(n = N, mu = mu, Sigma = cov_matrix)\n",
    "  # generate X with polynomial: (x1, x2, x3, x1^2, x2^2, x3^2)\n",
    "  poly_max <- 2\n",
    "  X <- reduce( c(1,1:poly_max), \n",
    "               function(X, poly)\n",
    "                 cbind(X, mvnorm_data[,1]^poly, mvnorm_data[,2]^poly, mvnorm_data[,3]^poly)\n",
    "  ) %>% subset(select = -c(1))\n",
    "  if(poly_max == 1) {\n",
    "    colnames(X) <- c(\"x1\",\"x2\",\"x3\")\n",
    "  } else {\n",
    "    colnames(X) <- rep(c(\"x1\",\"x2\",\"x3\"), poly_max - 1) %>%\n",
    "      paste0(c(rep(\"\", 3),rep(paste0(\"^\", 2:poly_max), each = 3)))\n",
    "  }\n",
    "  \n",
    "  D <- as.integer(mvnorm_data[,4] > 0)\n",
    "  X <- cbind(X, D)\n",
    "  eps <- rnorm(N, 0, 0.065)\n",
    "  y <- X %*% beta + eps\n",
    "  X <- subset(X, select = c(x1, x2, x3, D))\n",
    "  \n",
    "  beta.true <- 0.02\n",
    "  return(list(X=X, y=y, d=mvnorm_data[,4], beta.true=beta.true))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model2\n",
    "name <- \"model 2\"\n",
    "i <- 2\n",
    "\n",
    "# generate plot data\n",
    "sim.data <- simulation(sim.times = 1, data.size = data.size1, dgp_func)\n",
    "# sim.data <- sim.data.list1[[i]] # for replay\n",
    "sim.data.list1[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# bias line plot\n",
    "plot_bias <- ggplot(sim.data, aes(N)) +\n",
    "    geom_line(aes(y = bias, color = method)) +\n",
    "    ylim(min(sim.data$bias), max(sim.data$bias)) +\n",
    "    labs(title = paste0(name, \" bias\"))\n",
    "print(plot_bias)\n",
    "\n",
    "# ATE line plot\n",
    "plot_ATE <- ggplot(sim.data, aes(N)) +\n",
    "    geom_line(aes(y = ATE, color = method), cex = 1) +\n",
    "    geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper, fill = method), alpha = 0.1) +\n",
    "    geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "    ylim(min(sim.data$CI_lower), max(sim.data$CI_upper)) +\n",
    "    labs(title = paste0(name, \" ATE\"))\n",
    "print(plot_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　As sample size increases, causal forest works better than small sample size case and both OLS and causal forest decrease their variance (improve precision) in this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model2\n",
    "name <- \"model 2\"\n",
    "i <- 2\n",
    "\n",
    "sim.data <- simulation(sim.times = 1000, data.size = data.size2, dgp_func)\n",
    "# sim.data <- sim.data.list2[[i]] # for replay\n",
    "sim.data.list2[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# generate point and box plot for every data size\n",
    "ATE_point_plot.list <- list()\n",
    "ATE_box_plot.list <- list()\n",
    "for(j in 1:length(data.size2)){\n",
    "    N <- data.size2[j]\n",
    "    plot.heigth <- max(beta.true - min(sim.data$ATE), max(sim.data$ATE) - beta.true)\n",
    "    ATE_point_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(sim.time)) +\n",
    "      geom_point(aes(y = ATE, color = method, shape = method)) +\n",
    "      geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "      ylim(beta.true - plot.heigth, beta.true + plot.heigth) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = \"iteration\", y = \"ATE\")\n",
    "\n",
    "    ATE_box_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(method)) +\n",
    "      geom_boxplot(aes(y = ATE, color = method)) +\n",
    "      ylim(min(sim.data$ATE), max(sim.data$ATE)) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = NULL)\n",
    "}\n",
    "title <- ggdraw() + \n",
    "    draw_label(name, fontface = 'bold', x = 0, hjust = 0) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 20))\n",
    "ATE_point_plot <- plot_grid(plotlist = ATE_point_plot.list)\n",
    "ATE_box_plot <- plot_grid(plotlist = ATE_box_plot.list)\n",
    "# ATE_point.png\n",
    "print(plot_grid(title, ATE_point_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "# ATE_box.png\n",
    "print(plot_grid(title, ATE_box_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "\n",
    "# generate mean of simulation result data\n",
    "sim.data_grouped <- group_by(sim.data, method, N)\n",
    "mean_by_method_N <- summarize(sim.data_grouped, ATE = mean(ATE,na.rm=TRUE), RMSE = mean(RMSE,na.rm=TRUE), bias = mean(bias,na.rm=TRUE),\n",
    "                                   coverage = mean(coverage,na.rm=TRUE)) %>% mutate(model = name)\n",
    "mean_sim2 <- rbind(mean_sim2, mean_by_method_N)\n",
    "print(mean_by_method_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　Bias is higher for causal forest in small sample size, then it performs better as sample size increases. The reason is listed above that causal forest needs large data to perform well. As sample size increases, both OLS and causal forest work better in variance and coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tree\n",
    "dgp_func <- dgp_model2\n",
    "name <- \"model 2\"\n",
    "sim.data <- dgp_func(1000)\n",
    "result.cf<- forest(sim.data$X, sim.data$y, sim.data$beta.true)\n",
    "plot(result.cf$tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: with interaction terms \n",
    "$$y=0.05 x_{1}-0.005 x_{2}+0.01 x_{3} + 0.02D + 0.01x_{1}D + 0.001x_2D + 0.002x_1x_2D + \\varepsilon$$\n",
    "　　In model 3 we have omitted variable problem. Because of the heterogeneous design, causal forest should perform better than OLS. As can be seen from results, OLS has high bias in every specification and, as sample size increases, worse coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 3 ###\n",
    "# y = 0.05x1 + 0.005x2 + 0.01x3 + 0.02D + tau1*x1*D + tau2*x2*D + tau3*x1*x2*D + eps\n",
    "dgp_model3 <- function(N){\n",
    "  # mean, standard deviation, correlation matrix for generate (x1,x2,x3,d) using mvrnorm\n",
    "  mu <- c(1.40, 5.50, 0.10, 0.20)\n",
    "  sd <- c(1.00, 1.50, 0.30, 0.30)\n",
    "  cor_matrix <- matrix(c( 1.00,-0.05,-0.30, 0.15,\n",
    "                         -0.05, 1.00, 0.20, 0.35,\n",
    "                         -0.30, 0.20, 1.00, 0.50,\n",
    "                          0.15, 0.35, 0.50, 1.00), nrow = 4, ncol = 4)\n",
    "  beta <- c(0.05, -0.005, 0.01, 0.02) # for x1,x2,x3,D\n",
    "  tau <- c(0.01, 0.001, 0.002)\n",
    "  # gerate covariation matrix using standard error and correlation matrix\n",
    "  cov_matrix <- diag(sd) %*% cor_matrix %*% diag(sd)\n",
    "  # generate x1,x2,x3,d\n",
    "  mvnorm_data <- mvrnorm(n = N, mu = mu, Sigma = cov_matrix)\n",
    "  # generate X with polynomial: (x1, x2, x3)\n",
    "  poly_max <- 1\n",
    "  X <- reduce( c(1,1:poly_max), \n",
    "               function(X, poly)\n",
    "                 cbind(X, mvnorm_data[,1]^poly, mvnorm_data[,2]^poly, mvnorm_data[,3]^poly)\n",
    "  ) %>% subset(select = -c(1))\n",
    "  if(poly_max == 1) {\n",
    "    colnames(X) <- c(\"x1\",\"x2\",\"x3\")\n",
    "  } else {\n",
    "    colnames(X) <- rep(c(\"x1\",\"x2\",\"x3\"), poly_max - 1) %>%\n",
    "      paste0(c(rep(\"\", 3),rep(paste0(\"^\", 2:poly_max), each = 3)))\n",
    "  }\n",
    "  \n",
    "  D <- as.integer(mvnorm_data[,4] > 0)\n",
    "  X <- cbind(X, D)\n",
    "  eps <- rnorm(N, 0, 0.065)\n",
    "  y <- X %*% beta + eps\n",
    "  \n",
    "  # add intersection\n",
    "  X_D <- cbind(x1_D = X[,\"x1\"] * D, x2_D = X[,\"x2\"] * D, x1_x2_D = X[,\"x1\"]*X[,\"x2\"]*D)\n",
    "  y <- y + X_D %*% tau\n",
    "  \n",
    "  X <- subset(X, select = c(x1, x2, x3, D))\n",
    "  \n",
    "  beta.true <- 0.02 + tau %*% c(mu[1:2], (mu[1]*mu[2] + cov_matrix[1,2])) # E(X1)*E(X2)+Cov(X1,X2)=E(X1X2)\n",
    "  return(list(X=X, y=y, d=mvnorm_data[,4], beta.true=beta.true))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model3\n",
    "name <- \"model 3\"\n",
    "i <- 3\n",
    "\n",
    "# generate plot data\n",
    "sim.data <- simulation(sim.times = 1, data.size = data.size1, dgp_func)\n",
    "# sim.data <- sim.data.list1[[i]] # for replay\n",
    "sim.data.list1[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# bias line plot\n",
    "plot_bias <- ggplot(sim.data, aes(N)) +\n",
    "    geom_line(aes(y = bias, color = method)) +\n",
    "    ylim(min(sim.data$bias), max(sim.data$bias)) +\n",
    "    labs(title = paste0(name, \" bias\"))\n",
    "print(plot_bias)\n",
    "\n",
    "# ATE line plot\n",
    "plot_ATE <- ggplot(sim.data, aes(N)) +\n",
    "    geom_line(aes(y = ATE, color = method), cex = 1) +\n",
    "    geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper, fill = method), alpha = 0.1) +\n",
    "    geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "    ylim(min(sim.data$CI_lower), max(sim.data$CI_upper)) +\n",
    "    labs(title = paste0(name, \" ATE\"))\n",
    "print(plot_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model3\n",
    "name <- \"model 3\"\n",
    "i <- 3\n",
    "\n",
    "sim.data <- simulation(sim.times = 1000, data.size = data.size2, dgp_func)\n",
    "# sim.data <- sim.data.list2[[i]] # for replay\n",
    "sim.data.list2[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# generate point and box plot for every data size\n",
    "ATE_point_plot.list <- list()\n",
    "ATE_box_plot.list <- list()\n",
    "for(j in 1:length(data.size2)){\n",
    "    N <- data.size2[j]\n",
    "    plot.heigth <- max(beta.true - min(sim.data$ATE), max(sim.data$ATE) - beta.true)\n",
    "    ATE_point_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(sim.time)) +\n",
    "      geom_point(aes(y = ATE, color = method, shape = method)) +\n",
    "      geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "      ylim(beta.true - plot.heigth, beta.true + plot.heigth) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = \"iteration\", y = \"ATE\")\n",
    "\n",
    "    ATE_box_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(method)) +\n",
    "      geom_boxplot(aes(y = ATE, color = method)) +\n",
    "      ylim(min(sim.data$ATE), max(sim.data$ATE)) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = NULL)\n",
    "}\n",
    "title <- ggdraw() + \n",
    "    draw_label(name, fontface = 'bold', x = 0, hjust = 0) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 20))\n",
    "ATE_point_plot <- plot_grid(plotlist = ATE_point_plot.list)\n",
    "ATE_box_plot <- plot_grid(plotlist = ATE_box_plot.list)\n",
    "# ATE_point.png\n",
    "print(plot_grid(title, ATE_point_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "# ATE_box.png\n",
    "print(plot_grid(title, ATE_box_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "\n",
    "# generate mean of simulation result data\n",
    "sim.data_grouped <- group_by(sim.data, method, N)\n",
    "mean_by_method_N <- summarize(sim.data_grouped, ATE = mean(ATE,na.rm=TRUE), RMSE = mean(RMSE,na.rm=TRUE), bias = mean(bias,na.rm=TRUE),\n",
    "                                   coverage = mean(coverage,na.rm=TRUE)) %>% mutate(model = name)\n",
    "mean_sim2 <- rbind(mean_sim2, mean_by_method_N)\n",
    "print(mean_by_method_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tree\n",
    "dgp_func <- dgp_model3\n",
    "name <- \"model 3\"\n",
    "sim.data <- dgp_func(1000)\n",
    "result.cf<- forest(sim.data$X, sim.data$y, sim.data$beta.true)\n",
    "plot(result.cf$tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *comparison of the tree plots*\n",
    "　　We can see from the tree plots that tree branches increase from model 1 to 3, and meanwhile bias decreases. From left to right are plots for Model 1 to model 3 respectively, we can see that bias of causal forest becomes smaller in this process. (True ATE is the red line, estimated ATE is the blue line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model <- list(dgp_model1, dgp_model2, dgp_model3)\n",
    "model_names <- c(\"model 1\", \"model 2\", \"model 3\")\n",
    "\n",
    "for(i in c(1:length(sim_model))){\n",
    "  dgp_func <- sim_model[[i]]\n",
    "  name <- model_names[i]\n",
    "  sim.data <- dgp_func(1000)\n",
    "  result.cf<- forest(sim.data$X, sim.data$y, sim.data$beta.true)\n",
    "  # Evaluate the estimate using a histogram\n",
    "  print(ggplot(data.frame(effect=result.cf$tau.hat, y=sim.data$y, treated=sim.data$X[,\"D\"]), aes(x=effect)) +\n",
    "    geom_histogram(bins=60) +\n",
    "    geom_vline(xintercept=result.cf$ATE, linetype=\"dotted\", color=\"blue\", size=1.5) +\n",
    "    geom_vline(xintercept=sim.data$beta.true, color = \"red\", size=1.5) +\n",
    "    labs(title = paste0(name, \" tau.hat histogram\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　Next step we will calculate CATE value for x1 ad x2, and present it in rainbow plot and 3D plot. I equally divide the simulation into 50 partitions with sample size of 500000, but there are missing data due to the Gaussian distribution of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　Use function \"CATE\" to caculate CATE for specify x1 and x2 groups. Since x1 and x2 is continuous, we can't get CATE from value of x1 and x2. I divide the simulation into 50 partitions, and use the mean of every partition to stand for x1 and x2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATE <- function(dgp.data, x1_groups, x2_groups, model_name){\n",
    "  \n",
    "  x1_group_levels <- sort(unique(x1_groups))\n",
    "  x1_value_levels <- map_dbl(x1_group_levels, function(x1_group) mean(dgp.data$X[x1_groups==x1_group,\"x1\"])) # value equals mean of x1 in its group\n",
    "  x2_group_levels <- sort(unique(x2_groups))\n",
    "  x2_value_levels <- map_dbl(x2_group_levels, function(x2_group) mean(dgp.data$X[x2_groups==x2_group,\"x2\"]))\n",
    "  \n",
    "  CATE.data <- data.frame(ATE = rep(NA, length(x1_group_levels) * length(x2_group_levels) * 2),\n",
    "                        method = factor(x=rep(c(\"ols\", \"forest\"), length(x1_group_levels) * length(x2_group_levels)), levels = c(\"ols\", \"forest\")),\n",
    "                        x2_group = rep(x2_group_levels, each = 2, times = length(x1_group_levels)),\n",
    "                        x1_group = rep(x1_group_levels, each = 2 * length(x2_group_levels)),\n",
    "                        x2_value = rep(x2_value_levels, each = 2, times = length(x1_value_levels)),\n",
    "                        x1_value = rep(x1_value_levels, each = 2 * length(x2_value_levels)))\n",
    "  CATE.matrix.forest <- matrix(NA, nrow = length(x1_value_levels), ncol = length(x2_value_levels), dimnames = list(x1_value_levels,x2_value_levels))\n",
    "  CATE.matrix.ols <- matrix(NA, nrow = length(x1_value_levels), ncol = length(x2_value_levels), dimnames = list(x1_value_levels,x2_value_levels))\n",
    "  CATE.matrix.beta_true <- matrix(NA, nrow = length(x1_value_levels), ncol = length(x2_value_levels), dimnames = list(x1_value_levels,x2_value_levels))\n",
    "  index <- 1\n",
    "  for (i in 1:length(x1_group_levels)) {\n",
    "    for(j in 1:length(x2_group_levels)) {\n",
    "      x1_group <- x1_group_levels[i]\n",
    "      x2_group <- x2_group_levels[j]\n",
    "      \n",
    "      sub.X <- dgp.data$X[(x1_groups == x1_group & x2_groups == x2_group),]\n",
    "      sub.y <- dgp.data$y[(x1_groups == x1_group & x2_groups == x2_group)]\n",
    "      \n",
    "      if(length(sub.y) > 4){\n",
    "        if(sum(sub.X[,\"D\"]) != 0 && sum(sub.X[,\"D\"]) != nrow(sub.X)){\n",
    "          result.ols <- ols(sub.X, sub.y, dgp.data$beta.true)\n",
    "          result.cf <- forest(sub.X, sub.y, dgp.data$beta.true)\n",
    "          \n",
    "          CATE.data$ATE[index] <- result.ols$ATE\n",
    "          CATE.data$ATE[index+1] <- result.cf$ATE\n",
    "          \n",
    "          CATE.matrix.ols[i,j] <- result.ols$ATE\n",
    "          CATE.matrix.forest[i,j] <- result.cf$ATE\n",
    "          \n",
    "          if(model_name == \"model 3\"){\n",
    "            CATE.matrix.beta_true[i,j] <- 0.02 + c(0.01, 0.001, 0.002) %*% c(mean(sub.X[,\"x1\"]), mean(sub.X[,\"x2\"]), mean(sub.X[,\"x1\"]*sub.X[,\"x2\"]))\n",
    "          } else if (model_name == \"model 4\"){\n",
    "            CATE.matrix.beta_true[i,j] <- 0.02 + c(0.1, 0.1, -0.02, -0.01, 0.01) %*% \n",
    "              c(mean(sub.X[,\"x1\"]), mean(sub.X[,\"x2\"]), mean(sub.X[,\"x1\"]^2), mean(sub.X[,\"x2\"]^2), mean(sub.X[,\"x1\"]*sub.X[,\"x2\"]))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      index <- index + 2\n",
    "    }\n",
    "  }\n",
    "  return(list(CATE.data = CATE.data, CATE.matrix.forest = CATE.matrix.forest, CATE.matrix.ols = CATE.matrix.ols, CATE.matrix.beta_true = CATE.matrix.beta_true, x1_value_levels = x1_value_levels, x2_value_levels = x2_value_levels))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model3\n",
    "name <- \"model 3\"\n",
    "\n",
    "dgp.data <- dgp_func(500000)\n",
    "CATE.result <- CATE(dgp.data, ntile(dgp.data$X[,\"x1\"],50), ntile(dgp.data$X[,\"x2\"],50), name)\n",
    "\n",
    "# rainbow plot\n",
    "print(ggplot(subset(CATE.result$CATE.data, method==\"forest\"), aes(x=x1_group, y=x2_group, color = ATE)) +\n",
    "      geom_point(size = 4) +\n",
    "      scale_color_gradientn(colours = rainbow(10)) +\n",
    "      labs(title = paste0(name, \" CATE rainbow of forest\")))\n",
    "\n",
    "# box plot\n",
    "box.plot.data <- CATE.result$CATE.data %>% subset(ATE < 2 & method==\"forest\") %>% mutate(x1_value = as.factor(.$x1_value))\n",
    "print(ggplot(box.plot.data, aes(x1_value)) +\n",
    "      geom_boxplot(aes(y = ATE)) +\n",
    "      labs(title = paste0(name, \" CATE boxplot of forest\")))\n",
    "\n",
    "# Gridded Bivariate Interpolation plot by package \"akima\"\n",
    "im <- with(CATE.result$CATE.data %>% subset(method == \"forest\" & !is.na(ATE)), interp(x1_value,x2_value,ATE))\n",
    "with(im,image(x,y,z, xlab = \"x1 value\", ylab = \"x2 value\"))\n",
    "\n",
    "# 3D plot by package \"plotly\"\n",
    "# plotly_forest\n",
    "plot_ly(x=CATE.result$x1_value_levels,y=CATE.result$x2_value_levels,z=CATE.result$CATE.matrix.forest, type=\"surface\")\n",
    "# plotly_ols\n",
    "plot_ly(x=CATE.result$x1_value_levels,y=CATE.result$x2_value_levels,z=CATE.result$CATE.matrix.ols, type=\"surface\")\n",
    "# plotly_true\n",
    "plot_ly(x=CATE.result$x1_value_levels,y=CATE.result$x2_value_levels,z=CATE.result$CATE.matrix.beta_true, type=\"surface\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: with polynomials and interaction terms\n",
    "$$y=0.05 x_1-0.005 x_2+0.01 x_3 + 0.02D + 0.01x_1D + 0.001x_2D -0.02x_1^2D-0.01x_2^2D+0.01x_1x_2D+ \\varepsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 4 ###\n",
    "# y = 0.05x1 + 0.005x2 + 0.01x3 + 0.02D + tau1*x1*D + tau2*x2*D + tau3*x1^2*D + tau4*x2^2*D + tau5*x1*x2*D + eps\n",
    "dgp_model4 <- function(N){\n",
    "  # mean, standard deviation, correlation matrix for generate (x1,x2,x3,d) using mvrnorm\n",
    "  mu <- c(1.40, 5.50, 0.10, 0.20)\n",
    "  sd <- c(1.00, 1.50, 0.30, 0.30)\n",
    "  cor_matrix <- matrix(c( 1.00,-0.05,-0.30, 0.15,\n",
    "                         -0.05, 1.00, 0.20, 0.35,\n",
    "                         -0.30, 0.20, 1.00, 0.50,\n",
    "                          0.15, 0.35, 0.50, 1.00), nrow = 4, ncol = 4)\n",
    "  beta <- c(0.05, -0.005, 0.01, 0.02) # for x1,x2,x3,D\n",
    "  tau <- c(0.1, 0.1, -0.02, -0.01, 0.01)\n",
    "  # gerate covariation matrix using standard error and correlation matrix\n",
    "  cov_matrix <- diag(sd) %*% cor_matrix %*% diag(sd)\n",
    "  # generate x1,x2,x3,d\n",
    "  mvnorm_data <- mvrnorm(n = N, mu = mu, Sigma = cov_matrix)\n",
    "  # generate X: (x1, x2, x3)\n",
    "  poly_max <- 1\n",
    "  X <- reduce( c(1,1:poly_max), \n",
    "               function(X, poly)\n",
    "                 cbind(X, mvnorm_data[,1]^poly, mvnorm_data[,2]^poly, mvnorm_data[,3]^poly)\n",
    "  ) %>% subset(select = -c(1))\n",
    "  if(poly_max == 1) {\n",
    "    colnames(X) <- c(\"x1\",\"x2\",\"x3\")\n",
    "  } else {\n",
    "    colnames(X) <- rep(c(\"x1\",\"x2\",\"x3\"), poly_max - 1) %>%\n",
    "      paste0(c(rep(\"\", 3),rep(paste0(\"^\", 2:poly_max), each = 3)))\n",
    "  }\n",
    "  \n",
    "  D <- as.integer(mvnorm_data[,4] > 0)\n",
    "  X <- cbind(X, D)\n",
    "  eps <- rnorm(N, 0, 0.065)\n",
    "  y <- X %*% beta + eps\n",
    "  \n",
    "  # add intersection\n",
    "  X_D <- cbind(x1_D = X[,\"x1\"] * D, x2_D = X[,\"x2\"] * D, x12_D = X[,\"x1\"]^2 * D, x22_D = X[,\"x2\"]^2 * D, x1_x2_D = X[,\"x1\"] * X[,\"x2\"] * D)\n",
    "  y <- y + X_D %*% tau\n",
    "  \n",
    "  X <- subset(X, select = c(x1, x2, x3, D))\n",
    "  \n",
    "  beta.true <- 0.02 + tau %*% c(mu[1:2], (mu[1:2]^2 + sd[1:2]^2), (mu[1]*mu[2] + cov_matrix[1,2]))\n",
    "  return(list(X=X, y=y, d=mvnorm_data[,4], beta.true=beta.true))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model4\n",
    "name <- \"model 4\"\n",
    "i <- 4\n",
    "\n",
    "sim.data <- simulation(sim.times = 1000, data.size = data.size2, dgp_func)\n",
    "# sim.data <- sim.data.list2[[i]] # for replay\n",
    "sim.data.list2[[i]] <- sim.data\n",
    "beta.true <- dgp_func(2)$beta.true\n",
    "\n",
    "# generate point and box plot for every data size\n",
    "ATE_point_plot.list <- list()\n",
    "ATE_box_plot.list <- list()\n",
    "for(j in 1:length(data.size2)){\n",
    "    N <- data.size2[j]\n",
    "    plot.heigth <- max(beta.true - min(sim.data$ATE), max(sim.data$ATE) - beta.true)\n",
    "    ATE_point_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(sim.time)) +\n",
    "      geom_point(aes(y = ATE, color = method, shape = method)) +\n",
    "      geom_hline(yintercept = beta.true, color = I(\"black\")) +\n",
    "      ylim(beta.true - plot.heigth, beta.true + plot.heigth) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = \"iteration\", y = \"ATE\")\n",
    "\n",
    "    ATE_box_plot.list[[j]] <- ggplot(sim.data[sim.data$N==N,], aes(method)) +\n",
    "      geom_boxplot(aes(y = ATE, color = method)) +\n",
    "      ylim(min(sim.data$ATE), max(sim.data$ATE)) +\n",
    "      labs(subtitle = paste0(\"sample size = \", N), x = NULL)\n",
    "}\n",
    "title <- ggdraw() + \n",
    "    draw_label(name, fontface = 'bold', x = 0, hjust = 0) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 20))\n",
    "ATE_point_plot <- plot_grid(plotlist = ATE_point_plot.list)\n",
    "ATE_box_plot <- plot_grid(plotlist = ATE_box_plot.list)\n",
    "# ATE_point.png\n",
    "print(plot_grid(title, ATE_point_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "# ATE_box.png\n",
    "print(plot_grid(title, ATE_box_plot, ncol = 1, rel_heights = c(0.1, 1)))\n",
    "\n",
    "# generate mean of simulation result data\n",
    "sim.data_grouped <- group_by(sim.data, method, N)\n",
    "mean_by_method_N <- summarize(sim.data_grouped, ATE = mean(ATE,na.rm=TRUE), RMSE = mean(RMSE,na.rm=TRUE), bias = mean(bias,na.rm=TRUE),\n",
    "                                   coverage = mean(coverage,na.rm=TRUE)) %>% mutate(model = name)\n",
    "mean_sim2 <- rbind(mean_sim2, mean_by_method_N)\n",
    "print(mean_by_method_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp_func <- dgp_model4\n",
    "name <- \"model 4\"\n",
    "\n",
    "dgp.data <- dgp_func(500000)\n",
    "CATE.result <- CATE(dgp.data, ntile(dgp.data$X[,\"x1\"],50), ntile(dgp.data$X[,\"x2\"],50), name)\n",
    "\n",
    "# rainbow plot\n",
    "print(ggplot(subset(CATE.result$CATE.data, method==\"forest\"), aes(x=x1_group, y=x2_group, color = ATE)) +\n",
    "      geom_point(size = 4) +\n",
    "      scale_color_gradientn(colours = rainbow(10)) +\n",
    "      labs(title = paste0(name, \" CATE rainbow of forest\")))\n",
    "\n",
    "# box plot\n",
    "box.plot.data <- CATE.result$CATE.data %>% subset(ATE < 2 & method==\"forest\") %>% mutate(x1_value = as.factor(.$x1_value))\n",
    "print(ggplot(box.plot.data, aes(x1_value)) +\n",
    "      geom_boxplot(aes(y = ATE)) +\n",
    "      labs(title = paste0(name, \" CATE boxplot of forest\")))\n",
    "\n",
    "# Gridded Bivariate Interpolation plot by package \"akima\"\n",
    "im <- with(CATE.result$CATE.data %>% subset(method == \"forest\" & !is.na(ATE)), interp(x1_value,x2_value,ATE))\n",
    "with(im,image(x,y,z, xlab = \"x1 value\", ylab = \"x2 value\"))\n",
    "\n",
    "# 3D plot by package \"plotly\"\n",
    "# plotly_forest\n",
    "plot_ly(x=CATE.result$x1_value_levels,y=CATE.result$x2_value_levels,z=CATE.result$CATE.matrix.forest, type=\"surface\")\n",
    "# plotly_ols\n",
    "plot_ly(x=CATE.result$x1_value_levels,y=CATE.result$x2_value_levels,z=CATE.result$CATE.matrix.ols, type=\"surface\")\n",
    "# plotly_true\n",
    "plot_ly(x=CATE.result$x1_value_levels,y=CATE.result$x2_value_levels,z=CATE.result$CATE.matrix.beta_true, type=\"surface\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by the aggerated box plot for 4 models, we can have a clear look about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot all in one for sim2\n",
    "select.model <- c(\"model 1\", \"model 2\", \"model 3\", \"model 4\")\n",
    "select.data.size <- c(1000, 5000, 10000)\n",
    "model.box_plot.list <- list()\n",
    "for(model_name in select.model){\n",
    "  sim.data <- sim.data.list2[[which(model_name == model_names)]]\n",
    "  sim.data <- sim.data[sim.data$N %in% select.data.size,]\n",
    "  model.box_plot.list[[I(model_name)]] <- ggplot(sim.data, aes(method)) +\n",
    "    geom_boxplot(aes(y = ATE, color = method)) +\n",
    "    ylim(min(sim.data$ATE), max(sim.data$ATE)) +\n",
    "    facet_wrap(~N, nrow = 1) +\n",
    "    labs(title = model_name, x = NULL)\n",
    "}\n",
    "print(plot_grid(plotlist = model.box_plot.list, align = \"hv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Application\n",
    "　　As we can see from the project results, causal forest treatment has great extendibility and it has lots of empirical applications. For example, the essay I refer to is about an application of causal forest in corporate finance. Here I list two reasons for its goodness as an estimating tool:  \n",
    "　　First, many questions in economics or finance involve evaluating the treatment effect of a binary status or decision, in which case we need to deal with treatment effect heterogeneity. This is the type of question causal forest is designed to address.  \n",
    "　　Second, plenty of macroeconomic studies tend to have large data to deal with, thus providing a sufficient sample size. Our simulations show the importance of sample size in a causal forest estimation to recovering unbiased treatment effects, and confirm sample sizes as small as 5,000 to 15,000 are sufficient for a causal forest estimation with low error.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
